{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 2 lab vaja\n",
    "\n",
    "### Napovedovanje stopnje kriminala z uporabo metode ponovnega vzorčenja in izbire atributov\n",
    "\n",
    "V tej nalogi raziskujemo metode ponovnega vzorčenja za ocenjevanje modelov in izbiro atributov za napovedovanje stopnje kriminala na podlagi različnih atributov. Uporabljamo podatkovno zbirko \"Communities and Crime\" in uporabljamo tehnike linearne regresije. (ker je najenostavnejša)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predobdelava podatkov\n",
    "\n",
    "Začnemo z nalaganjem podatkovne zbirke in predobdelavo za linearno regresijo:\n",
    "\n",
    "- **Ciljna spremenljivka**: `ViolentCrimesPerPop` (atribut 127)\n",
    "- **Odstranjeni atributi**: `state`, `county`, `community`, `community name`, in `fold` (stolpci 1 do 5)\n",
    "\n",
    "Manjkajoče vrednosti obravnavamo tako, da jih nadomestimo s povprečjem njihovih ustreznih stolpcev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_file_path = \"communities+and+crime/communities.data\"\n",
    "columns_to_remove = ['attr_0', 'attr_1', 'attr_2', 'attr_3', 'attr_4']  \n",
    "target_column = 'attr_127'  \n",
    "\n",
    "data = pd.read_csv(data_file_path, header=None, na_values='?')\n",
    "data.columns = [f'attr_{i}' for i in range(data.shape[1])]\n",
    "data = data.drop(columns=columns_to_remove)\n",
    "\n",
    "\n",
    "data = data.fillna(data.mean())\n",
    "\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metode navzkrižne validacije in metode leave-one-out\n",
    "\n",
    "Implementiramo:\n",
    "\n",
    "- **Navzkrižna validacija**: Razdelitev podatkovne zbirke na `k` delov (običajno je najboljša 5-kratna ali 10-kratna delitev) za ocenjevanje uspešnosti modela.\n",
    "- **Leave-One-Out navzkrižna validacija**: Poseben primer navzkrižne validacije, kjer je `k` enako številu opazovanj. Ta metoda ima preveliko varianco.\n",
    "\n",
    "Te metode pomagajo oceniti splošno uporabnost našega modela linearne regresije.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.18907747633998667)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_validation(X, y, k=5):\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=k)\n",
    "    model = LinearRegression()\n",
    "    scores = []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        scores.append(mean_squared_error(y_val, y_pred))\n",
    "    return np.mean(scores)\n",
    "cross_validation(X, y, k=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.2986172439516377)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def leave_one_out(X, y):\n",
    "    from sklearn.model_selection import LeaveOneOut\n",
    "    loo = LeaveOneOut()\n",
    "    model = LinearRegression()\n",
    "    scores = []\n",
    "    for train_index, val_index in loo.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        scores.append(mean_squared_error(y_val, y_pred))\n",
    "    return np.mean(scores)\n",
    "leave_one_out(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Izbira atributov z naprej usmerjeno selekcijo\n",
    "\n",
    "Implementiramo naprej usmerjeno selekcijo atributov, da identificiramo podmnožico lastnosti, ki najbolj prispevajo k napovedovanju stopnje kriminala.\n",
    "\n",
    "- **Uporabljena metrika**: R-kvadrat (`R²`)\n",
    "- **Kriterij za ustavitev**: Izboljšanje manjše od `0.001`\n",
    "\n",
    "Na vsakem koraku izberemo atribut, ki najbolj izboljša uspešnost modela glede na izbrano metriko.\n",
    "\n",
    "### About R-squared (R²)\n",
    "\n",
    "R-squared, also known as the coefficient of determination, is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. It provides an indication of the goodness of fit and how well the model explains the variability of the outcome data.\n",
    "\n",
    "- **Range**: R-squared values range from 0 to 1.\n",
    "  - **0**: Indicates that the model explains none of the variability of the response data around its mean.\n",
    "  - **1**: Indicates that the model explains all the variability of the response data around its mean.\n",
    "- **Interpretation**: \n",
    "  - A higher R-squared value indicates a better fit for the model.\n",
    "  - However, a high R-squared value does not necessarily mean the model is good. It is important to consider other metrics and validate the model with different datasets.\n",
    "\n",
    "We are selecting the variable that is most closely related to improving the R-squared value, thereby enhancing the model's ability to explain the variance in the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate: attr_49, Score: 0.5217378882227437, Improvement: inf\n",
      "Selected attr_49, Current Best Score: 0.5217378882227437\n",
      "Evaluating candidate: attr_8, Score: 0.6131370592366217, Improvement: 0.09139917101387796\n",
      "Selected attr_8, Current Best Score: 0.6131370592366217\n",
      "Evaluating candidate: attr_16, Score: 0.6290662293159336, Improvement: 0.01592917007931194\n",
      "Selected attr_16, Current Best Score: 0.6290662293159336\n",
      "Evaluating candidate: attr_54, Score: 0.6370152274288681, Improvement: 0.00794899811293448\n",
      "Selected attr_54, Current Best Score: 0.6370152274288681\n",
      "Evaluating candidate: attr_73, Score: 0.6451848153105901, Improvement: 0.008169587881722062\n",
      "Selected attr_73, Current Best Score: 0.6451848153105901\n",
      "Evaluating candidate: attr_12, Score: 0.6505539232280049, Improvement: 0.005369107917414739\n",
      "Selected attr_12, Current Best Score: 0.6505539232280049\n",
      "Evaluating candidate: attr_97, Score: 0.6547847405492455, Improvement: 0.004230817321240643\n",
      "Selected attr_97, Current Best Score: 0.6547847405492455\n",
      "Evaluating candidate: attr_65, Score: 0.6582372759343331, Improvement: 0.0034525353850876073\n",
      "Selected attr_65, Current Best Score: 0.6582372759343331\n",
      "Evaluating candidate: attr_107, Score: 0.6609711215500986, Improvement: 0.0027338456157655067\n",
      "Selected attr_107, Current Best Score: 0.6609711215500986\n",
      "Evaluating candidate: attr_23, Score: 0.6630686676287181, Improvement: 0.00209754607861945\n",
      "Selected attr_23, Current Best Score: 0.6630686676287181\n",
      "Evaluating candidate: attr_79, Score: 0.6650442301944937, Improvement: 0.0019755625657755793\n",
      "Selected attr_79, Current Best Score: 0.6650442301944937\n",
      "Evaluating candidate: attr_124, Score: 0.6667276017512471, Improvement: 0.0016833715567534657\n",
      "Selected attr_124, Current Best Score: 0.6667276017512471\n",
      "Evaluating candidate: attr_18, Score: 0.6679663990290624, Improvement: 0.0012387972778152845\n",
      "Selected attr_18, Current Best Score: 0.6679663990290624\n",
      "Evaluating candidate: attr_33, Score: 0.6709689299829407, Improvement: 0.0030025309538782574\n",
      "Selected attr_33, Current Best Score: 0.6709689299829407\n",
      "Evaluating candidate: attr_9, Score: 0.6726560999211812, Improvement: 0.0016871699382405847\n",
      "Selected attr_9, Current Best Score: 0.6726560999211812\n",
      "Evaluating candidate: attr_28, Score: 0.6737586416696482, Improvement: 0.001102541748466912\n",
      "Selected attr_28, Current Best Score: 0.6737586416696482\n",
      "Evaluating candidate: attr_30, Score: 0.6751041795675461, Improvement: 0.0013455378978979304\n",
      "Selected attr_30, Current Best Score: 0.6751041795675461\n",
      "Evaluating candidate: attr_53, Score: 0.6766806814554305, Improvement: 0.001576501887884385\n",
      "Selected attr_53, Current Best Score: 0.6766806814554305\n",
      "Evaluating candidate: attr_119, Score: 0.6781220773385617, Improvement: 0.0014413958831311913\n",
      "Selected attr_119, Current Best Score: 0.6781220773385617\n",
      "Evaluating candidate: attr_27, Score: 0.679093195862, Improvement: 0.0009711185234383413\n",
      "Selected Features: ['attr_49', 'attr_8', 'attr_16', 'attr_54', 'attr_73', 'attr_12', 'attr_97', 'attr_65', 'attr_107', 'attr_23', 'attr_79', 'attr_124', 'attr_18', 'attr_33', 'attr_9', 'attr_28', 'attr_30', 'attr_53', 'attr_119']\n",
      "X_train shape: (1595, 19)\n",
      "y_train shape: (1595,)\n",
      "Test MAE: 0.08766817735681658\n",
      "Test RMSE: 0.12416353535554474\n",
      "95% Confidence Interval for MAE: [0.08711007 0.09093913]\n"
     ]
    }
   ],
   "source": [
    "def forward_selection(X, y, metric='r2', stopping_criteria=0.001):\n",
    "    selected_features = []\n",
    "    remaining_features = list(X.columns)\n",
    "    \n",
    "    if metric == 'mse':\n",
    "        current_score = float('inf')\n",
    "    else:\n",
    "        current_score = -float('inf')\n",
    "    \n",
    "    while remaining_features:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining_features:\n",
    "            features_to_test = selected_features + [candidate]\n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                X[features_to_test], y, test_size=0.2, random_state=42\n",
    "            )\n",
    "            model = LinearRegression().fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_val)\n",
    "            \n",
    "            if metric == 'mse':\n",
    "                score = mean_squared_error(y_val, y_pred)\n",
    "            else:\n",
    "                score = model.score(X_val, y_val)\n",
    "            \n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        \n",
    "        if metric == 'mse':\n",
    "            best_new_score, best_candidate = min(scores_with_candidates, key=lambda x: x[0])\n",
    "            improvement = current_score - best_new_score\n",
    "        else:\n",
    "            best_new_score, best_candidate = max(scores_with_candidates, key=lambda x: x[0])\n",
    "            improvement = best_new_score - current_score\n",
    "        \n",
    "        print(f\"Evaluating candidate: {best_candidate}, Score: {best_new_score}, Improvement: {improvement}\")\n",
    "        \n",
    "        if improvement > stopping_criteria:\n",
    "            remaining_features.remove(best_candidate)\n",
    "            selected_features.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "            print(f\"Selected {best_candidate}, Current Best Score: {current_score}\")\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return selected_features\n",
    "\n",
    "selected_features = forward_selection(X, y, metric='r2', stopping_criteria=0.001)\n",
    "print(\"Selected Features:\", selected_features)\n",
    "\n",
    "if selected_features:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X[selected_features], y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    \n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"Test MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "    print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    bootstrap_results = []\n",
    "    n_iterations = 1000\n",
    "    for _ in range(n_iterations):\n",
    "        X_resample, y_resample = resample(X_train, y_train)\n",
    "        model = LinearRegression().fit(X_resample, y_resample)\n",
    "        y_pred = model.predict(X_test)\n",
    "        bootstrap_results.append(mean_absolute_error(y_test, y_pred))\n",
    "    \n",
    "    confidence_interval = np.percentile(bootstrap_results, [2.5, 97.5])\n",
    "    print(\"95% Confidence Interval for MAE:\", confidence_interval)\n",
    "else:\n",
    "    print(\"No features were selected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metoda bootstrap\n",
    "\n",
    "Uporabimo metodo bootstrap za oceno intervalov zaupanja v uspešnost našega modela:\n",
    "\n",
    "- **Ponovno vzorčenje**: Ustvarimo 1000 različnih učnih sklopov z vzorčenjem z vračanjem\n",
    "- **Usposobljeni modeli**: 1000 modelov linearne regresije\n",
    "- **Ocenjevanje uspešnosti**: Ocenimo MAE na testnem sklopu za vsak model\n",
    "- **Intervali zaupanja**: Izračunamo 95% interval zaupanja za MAE\n",
    "\n",
    "To nam pomaga razumeti variabilnost in zanesljivost, torej verjetnost uspešnosti našega modela. iz tega lahko tudi t stat izračunamo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval for MAE: [0.08696414 0.09071894]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "bootstrap_results = []\n",
    "n_iterations = 1000\n",
    "for _ in range(n_iterations):\n",
    "    X_resample, y_resample = resample(X_train, y_train)\n",
    "    model = LinearRegression().fit(X_resample, y_resample)\n",
    "    y_pred = model.predict(X_test)\n",
    "    bootstrap_results.append(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "confidence_interval = np.percentile(bootstrap_results, [2.5, 97.5])\n",
    "print(\"95% Confidence Interval for MAE:\", confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
